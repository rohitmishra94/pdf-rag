{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4364551650040c5a48fb017f6bb4e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0073a34d6dc24c93af21350fe5b917bf",
              "IPY_MODEL_f93e3ddb98bb493396312b178a555dca",
              "IPY_MODEL_2747f99740024630be498c2ca56272a4"
            ],
            "layout": "IPY_MODEL_3519a290cb814a5a851cc7f6a8dc0fc0"
          }
        },
        "0073a34d6dc24c93af21350fe5b917bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fb4517735874bdab27c88ba663cb063",
            "placeholder": "​",
            "style": "IPY_MODEL_df0ff1025ccf4750a4f17dc9a37394e8",
            "value": "Fetching 30 files: 100%"
          }
        },
        "f93e3ddb98bb493396312b178a555dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac2959c9e2049099dbc6b2a45e35dd9",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_812a4b0453fc468eb76e67def7e952bc",
            "value": 30
          }
        },
        "2747f99740024630be498c2ca56272a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b72e693ae9264722baacb09af3df01d7",
            "placeholder": "​",
            "style": "IPY_MODEL_1bb449f0950748f6a77343d3efe79425",
            "value": " 30/30 [00:00&lt;00:00, 1333.98it/s]"
          }
        },
        "3519a290cb814a5a851cc7f6a8dc0fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fb4517735874bdab27c88ba663cb063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0ff1025ccf4750a4f17dc9a37394e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aac2959c9e2049099dbc6b2a45e35dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812a4b0453fc468eb76e67def7e952bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b72e693ae9264722baacb09af3df01d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb449f0950748f6a77343d3efe79425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BVbUB8NDpGR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rohitmishra94/pdf-rag.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTXE6tI_Dx02",
        "outputId": "37325a14-ee48-48f7-8ba8-35e910ccb064"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pdf-rag'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 23 (delta 8), reused 12 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 304.64 KiB | 1.10 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/pdf-rag/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTz1QfIpDxro",
        "outputId": "b9d7b34f-aaef-4d10-c905-f8f258d79c79"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken==0.8.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/pdf-rag/requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: openai==1.59.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/pdf-rag/requirements.txt (line 2)) (1.59.5)\n",
            "Requirement already satisfied: chromadb==0.6.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/pdf-rag/requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: sentence-transformers==3.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/pdf-rag/requirements.txt (line 4)) (3.3.1)\n",
            "Requirement already satisfied: FlagEmbedding==1.3.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/pdf-rag/requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: pymupdf4llm==0.0.17 in /usr/local/lib/python3.10/dist-packages (from -r /content/pdf-rag/requirements.txt (line 6)) (0.0.17)\n",
            "Requirement already satisfied: tenacity==9.0.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/pdf-rag/requirements.txt (line 7)) (9.0.0)\n",
            "Requirement already satisfied: python-dotenv==1.0.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/pdf-rag/requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.8.0->-r /content/pdf-rag/requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.8.0->-r /content/pdf-rag/requirements.txt (line 1)) (2.32.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (2.10.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (3.7.5)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.69.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (31.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (3.10.13)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (13.9.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (11.1.0)\n",
            "Requirement already satisfied: datasets==2.19.0 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (2.19.0)\n",
            "Requirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: ir-datasets in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.5.9)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (5.29.3)\n",
            "Requirement already satisfied: pymupdf>=1.24.10 in /usr/local/lib/python3.10/dist-packages (from pymupdf4llm==0.0.17->-r /content/pdf-rag/requirements.txt (line 6)) (1.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (3.11.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (2.2.1)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.41.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (24.12.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.59.5->-r /content/pdf-rag/requirements.txt (line 2)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.8.0->-r /content/pdf-rag/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (3.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (14.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (4.12.3)\n",
            "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (2.5.1)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (5.3.0)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (2.6)\n",
            "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.1.9)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.2.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (2.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (1.18.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.3.1->-r /content/pdf-rag/requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0->FlagEmbedding==1.3.3->-r /content/pdf-rag/requirements.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.6.2->-r /content/pdf-rag/requirements.txt (line 3)) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -r /content/chromadb_folder"
      ],
      "metadata": {
        "id": "9ncGfUJhOc9S"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb.utils import embedding_functions\n",
        "from FlagEmbedding import FlagReranker\n",
        "import chromadb\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "from FlagEmbedding import BGEM3FlagModel\n",
        "import pymupdf4llm\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI, AsyncOpenAI\n",
        "import os\n",
        "from typing import List, Dict, Any, Optional\n",
        "import logging.config\n",
        "import json\n",
        "import asyncio\n",
        "from dotenv import load_dotenv\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "print('env variable loaded: ',load_dotenv('/content/env'))\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "AsyncClient = AsyncOpenAI()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b1-WR2nFNtP",
        "outputId": "026d7b91-d5f5-4d2c-8d16-ca33c72fbbfe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env variable loaded:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await check_pdf_page_for_index('/content/pdf-rag/handbook.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7y03nEmKfj5",
        "outputId": "2d476e27-c7e1-49fc-f923-d02f7c2e78b1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checking for index..\n",
            "index saved at  handbook.pdf_index.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/handbook.pdf_index.txt','r') as file:\n",
        "  f= file.readline().strip()\n",
        "f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "buWaZquJK24P",
        "outputId": "3af17e76-3d10-4f78-ffc9-75a499a8f3dd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/pdf-rag/handbook.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[1]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def embedding_function_bge(text_list):\n",
        "    return model.encode(text_list, return_dense=True)['dense_vecs']\n",
        "\n",
        "\n",
        "\n",
        "class MyEmbeddingFunction(EmbeddingFunction):\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        embeddings = embedding_function_bge(input)\n",
        "        return embeddings\n",
        "\n",
        "model = BGEM3FlagModel('BAAI/bge-m3',  use_fp16=True)\n",
        "default_ef = MyEmbeddingFunction()\n",
        "client = chromadb.PersistentClient(path=\"chromadb_folder\")\n",
        "\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "# embedding_function_bge(['iam there'])\n",
        "# default_ef(['iam there'])\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "def process_texts(texts, chunk_size=100, overlap=30):\n",
        "    \"\"\"Process a list of texts, splitting them into chunks of specified size with overlap,\n",
        "    and accumulating shorter texts.\"\"\"\n",
        "    accumulated_words = []  # Accumulate words from texts shorter than chunk_size\n",
        "    final_chunks = []  # Store the final chunks of text\n",
        "\n",
        "    for text in texts.split():\n",
        "        accumulated_words.append(text)\n",
        "\n",
        "        while len(accumulated_words) >= chunk_size:\n",
        "            # Take the first chunk_size words for the current chunk\n",
        "            chunk = \" \".join(accumulated_words[:chunk_size])\n",
        "            final_chunks.append(chunk)\n",
        "            # Remove words from the start of the accumulated_words, considering overlap\n",
        "            accumulated_words = accumulated_words[chunk_size - overlap:]\n",
        "\n",
        "    # If there are any remaining words, form the last chunk\n",
        "    if accumulated_words:\n",
        "        final_chunks.append(\" \".join(accumulated_words))\n",
        "\n",
        "    return final_chunks\n",
        "\n",
        "def get_unique_text_indices(text_list):\n",
        "    unique_texts = {}\n",
        "    unique_indices = []\n",
        "\n",
        "    for i, text in enumerate(text_list):\n",
        "        if text not in unique_texts:\n",
        "            unique_texts[text] = i\n",
        "            unique_indices.append(i)\n",
        "\n",
        "    return unique_indices\n",
        "\n",
        "def count_tokens(text: str, model: str = \"gpt-4o-mini\") -> int:\n",
        "\n",
        "    try:\n",
        "        # Get the tokenizer for the specified model\n",
        "        tokenizer = tiktoken.encoding_for_model(model)\n",
        "    except KeyError:\n",
        "        # Default to a generic encoding if the model is unknown\n",
        "        tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "    # Tokenize the text and return the token count\n",
        "    token_count = len(tokenizer.encode(text))\n",
        "    return token_count\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "import fitz\n",
        "check_pdf_prompt = ''' Analyze the page content and return True if page as table of content information.\n",
        "return json output {'toc': true or false}. pdf_page is\n",
        "'''\n",
        "async def check_pdf_page_for_index(pdf_path):\n",
        "    scanned_pages_dict = {}\n",
        "    doc = fitz.open(pdf_path)\n",
        "    doc_name = doc.name.split('/')[-1]\n",
        "    # Iterate through each page\n",
        "    print('checking for index..')\n",
        "    for page_num in range(10):\n",
        "        page = doc.load_page(page_num)  # Load the current page\n",
        "        text = page.get_text()\n",
        "        msg = [{\"role\": \"system\", \"content\": check_pdf_prompt + f'{text}'}]\n",
        "        response = await chat_completion_request(msg)\n",
        "        output = json.loads(response.choices[0].message.content)\n",
        "        # print(output)\n",
        "        scanned_pages_dict[page_num] = output['toc']\n",
        "    # return scanned_pages_dict\n",
        "\n",
        "    index_pages = [k for k,v in scanned_pages_dict.items() if v==True]\n",
        "    index_text = [doc.load_page(i).get_text() for i in index_pages]\n",
        "    if index_text:\n",
        "        collection_name = pdf_path.split('/')[-1]\n",
        "        with open(f'{collection_name}_index.txt','w') as f:\n",
        "            f.write(pdf_path+'\\n')\n",
        "            f.write('\\n'.join(index_text))\n",
        "            print('index saved at ',f'{collection_name}_index.txt')\n",
        "        return f'{collection_name}_index.txt'\n",
        "    else:\n",
        "      return 'no index found'\n",
        "\n",
        "# await check_pdf_page_for_index('pdf-rag/handbook.pdf')\n",
        "\n",
        "\n",
        "async def create_pdf_collection(pdf_path):\n",
        "    \"\"\"\n",
        "    Process a PDF file and add its chunks to a collection.\n",
        "\n",
        "    Args:\n",
        "        pdf_path: Path to the PDF file\n",
        "        collection: The collection object to add documents to\n",
        "    \"\"\"\n",
        "    try:\n",
        "        md_text = pymupdf4llm.to_markdown(pdf_path,show_progress=True)\n",
        "        _ = await check_pdf_page_for_index(pdf_path)\n",
        "        all_chunks = process_texts(md_text, chunk_size=500, overlap=50)\n",
        "        index_info = await check_pdf_page_for_index(pdf_path)\n",
        "        collection_name = pdf_path.split('/')[-1]\n",
        "        collection = client.get_or_create_collection(name=collection_name,embedding_function=default_ef)\n",
        "        logger.info(collection)\n",
        "\n",
        "        for idx, chunk in tqdm(enumerate(all_chunks)):\n",
        "            id_ = str(idx)\n",
        "            collection.add(\n",
        "                documents=[chunk],\n",
        "                ids=[id_]\n",
        "            )\n",
        "        status = 'success'\n",
        "        return status,collection_name,index_info\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating pdf collection: {str(e)}\", exc_info=True)\n",
        "        return f'Sorry for inconvenience. Error creating pdf collection. Please contact support.'\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "# create_pdf_collection('/workspace/test/pdf-rag/handbook.pdf')\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "def get_collections():\n",
        "    return client.list_collections()\n",
        "\n",
        "def load_collection(collection_name):\n",
        "    try:\n",
        "        collection = client.get_or_create_collection(name=collection_name,embedding_function=default_ef)\n",
        "        status = 'success'\n",
        "        return status, collection\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Collection load request failed: {str(e)}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "\n",
        "def get_full_context(query, collection, n_results=5, top=2):\n",
        "    logger.info(f'quering collection---> {collection}')\n",
        "\n",
        "    result = collection.query(query_texts = query,n_results=n_results)\n",
        "    texts = result['documents'][0]\n",
        "    ids = result['ids'][0]\n",
        "    unique_indices = get_unique_text_indices(texts)\n",
        "    unique_docs = [texts[x] for x in unique_indices]\n",
        "    unique_ids = [ids[x] for x in unique_indices]\n",
        "    ## colbert\n",
        "    query_col = model.encode([query],return_colbert_vecs=True)\n",
        "    docs_col = model.encode(unique_docs,return_colbert_vecs=True)\n",
        "    colber_scores = []\n",
        "    for vectors in docs_col['colbert_vecs']:\n",
        "        colber_scores.append(model.colbert_score(query_col['colbert_vecs'][0],vectors).numpy())\n",
        "\n",
        "    ## full_context_colbert\n",
        "    full_context_scores = []\n",
        "    full_context_ids = []\n",
        "    for id in unique_ids:\n",
        "        pre_id,post_id = str(int(id)-1), str(int(id)+1)\n",
        "        # print(pre_id,id,post_id)\n",
        "        full_context_ids.append([pre_id,id,post_id])\n",
        "        full_context=collection.get(ids=[f'{pre_id}',f'{id}',f'{post_id}'])['documents']\n",
        "        full_context = ''.join(full_context)\n",
        "        full_context_colber_vec = model.encode([full_context],return_colbert_vecs=True)\n",
        "        full_context_colber_score = model.colbert_score(query_col['colbert_vecs'][0],full_context_colber_vec['colbert_vecs'][0]).numpy()\n",
        "\n",
        "        full_context_scores.append(full_context_colber_score)\n",
        "\n",
        "    all_scores = [2*full_context_scores[i]+0.9*colber_scores[i] for i in range(len(colber_scores))]\n",
        "    sorted_indices = [index for index, _ in sorted(enumerate(all_scores), key=lambda x: x[1], reverse=True)]\n",
        "    top_context_ids_list = [full_context_ids[index] for index in sorted_indices][:top]\n",
        "    flattened_list = np.array(top_context_ids_list).flatten().tolist()\n",
        "    top_ids = list(set(flattened_list))\n",
        "    top_context = collection.get(ids=top_ids)['documents']\n",
        "\n",
        "    logger.info(f'context retrieved from collection---> {collection}')\n",
        "    return top_context, top_ids\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "\n",
        "async def generate_response(params: Dict[str, Any]) -> Any:\n",
        "    \"\"\"Generate response using OpenAI API with error handling and logging.\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Generating response with model: {params.get('model')}\")\n",
        "        response = await AsyncClient.chat.completions.create(**params)\n",
        "        logger.info(\"Response generated successfully\")\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating response: {str(e)}\", exc_info=True)\n",
        "        return f'Sorry for inconvenience. Please contact support.'\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
        "async def chat_completion_request(messages: List[Dict], model='gpt-4o-mini') -> Any:\n",
        "    \"\"\"Make a chat completion request with retry logic.\"\"\"\n",
        "    try:\n",
        "        params = {\n",
        "            'messages': messages,\n",
        "            'max_tokens': 1000,\n",
        "            'model': model,\n",
        "            'temperature': 0,\n",
        "            'response_format': {\"type\": \"json_object\"}\n",
        "        }\n",
        "\n",
        "        response = await generate_response(params)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Chat completion request failed: {str(e)}\", exc_info=True)\n",
        "        return f'Sorry for inconvenience. Please contact support.'\n",
        "\n",
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "async def get_toc_content(query,index_name):\n",
        "\n",
        "\n",
        "  with open(f'{index_name}','r') as f:\n",
        "    pdf_path = f.readline().strip()\n",
        "    content = f.read()\n",
        "    prompt = f'''\n",
        "  Your task is to return list of page no which may contain information regarding {query}\n",
        "  based on this table of content {content} output format: json page:[page no]\n",
        "  '''\n",
        "    msg = [{\"role\": \"system\", \"content\": prompt}]\n",
        "    response = await chat_completion_request(msg)\n",
        "    output = json.loads(response.choices[0].message.content)\n",
        "\n",
        "    doc = fitz.open(pdf_path)\n",
        "    print('looking for context at pages: ', output['page'])\n",
        "    context = [doc.load_page(page_num-1).get_text() for page_num in output['page']]\n",
        "\n",
        "    user_query = f'Based on below CONTEXT {context} ANSWER the query {query}'\n",
        "\n",
        "    system_instruction = '''Ideal Output Format\n",
        "The output should be a structured JSON blob that question with its corresponding answer.\n",
        "Answers should be word to word match if the question is a word to word match\n",
        "If the CONTEXT is insufficient, reply with “Data Not Available'''\n",
        "\n",
        "    msg = [{\"role\": \"system\", \"content\": system_instruction},{\"role\": \"user\", \"content\": user_query}]\n",
        "\n",
        "    response = await chat_completion_request(msg)\n",
        "    total_tokens = response.usage.total_tokens\n",
        "    output = json.loads(response.choices[0].message.content)\n",
        "\n",
        "    return output,total_tokens\n",
        "\n",
        "\n",
        "\n",
        "def check_file_exists(file_path):\n",
        "    return os.path.isfile(file_path)\n",
        "\n",
        "async def get_answer(query,collection_name):\n",
        "    # context = get_context(query,n_results=5,top_results=2,threshold = 0.5)\n",
        "\n",
        "    collection = client.get_or_create_collection(name=collection_name,embedding_function=default_ef)\n",
        "\n",
        "    context, context_idx = get_full_context(query, collection, n_results=5, top=2)\n",
        "    user_query = f'Based on below CONTEXT {context} ANSWER the query {query}'\n",
        "\n",
        "    system_instruction = '''Ideal Output Format\n",
        "The output should be a structured JSON blob that question with its corresponding answer.\n",
        "Answers should be word to word match if the question is a word to word match\n",
        "If the CONTEXT is insufficient, reply with “Data Not Available'''\n",
        "\n",
        "    msg = [{\"role\": \"system\", \"content\": system_instruction},{\"role\": \"user\", \"content\": user_query}]\n",
        "\n",
        "    response = await chat_completion_request(msg)\n",
        "    total_tokens = response.usage.total_tokens\n",
        "    output = json.loads(response.choices[0].message.content)\n",
        "\n",
        "    return output,total_tokens\n",
        "\n",
        "\n",
        "# In[22]:\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
        "async def chat_request(messages: List[Dict], tools=None, model='gpt-4o-mini', stream=False) -> Any:\n",
        "    \"\"\"Make a chat completion request with retry logic.\"\"\"\n",
        "    try:\n",
        "        params = {\n",
        "            'messages': messages,\n",
        "            'max_tokens': 1500,\n",
        "            'model': model,\n",
        "            'temperature': 0,\n",
        "            'tools': tools,\n",
        "            'tool_choice': \"auto\",\n",
        "            'stream': stream,\n",
        "        }\n",
        "        response = await generate_response(params)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Chat completion request failed: {str(e)}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_answer\",\n",
        "            \"description\": \"Use this function to get answers based on context documents from database to user questions. The documents are purely based on user db.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"User query in string.\",\n",
        "                    },\n",
        "                    \"collection\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"db collection name in string.\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"query\",\"collection\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_toc_content\",\n",
        "            \"description\": \"Use this function to get answers based on index path of document.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"User query in string.\",\n",
        "                    },\n",
        "                    \"index_name\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"index path in string.\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"query\",\"index_name\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"create_pdf_collection\",\n",
        "            \"description\": \"Use this function to create database collection from pdf file path\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"pdf_path\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"pdf_path in string.\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"pdf_path\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_collections\",\n",
        "            \"description\": \"Use this function to check exsiting collection in database\",\n",
        "\n",
        "        },\n",
        "    },\n",
        "]\n",
        "\n",
        "system_prompt = '''\n",
        "Your task is to answer user questions. The user can ask a single question or multiple questions.\n",
        "You have access to the below tools to return answers based on user single/multiple questions.\n",
        "\n",
        "# Tool\n",
        "\"name\": \"get_collections\",\n",
        "\"description\": \"Use this function to check exsiting collection in database\",\n",
        "\"name\": \"create_pdf_collection\",\n",
        "\"description\": \"Use this function to create database collection from pdf file path\",\n",
        "\"name\": \"get_answer\",\n",
        "\"description\": \"Use this function to get answers based on context documents from database to user questions. The documents are purely based on user db.\",\n",
        "\"name\": \"get_toc_content\",\n",
        "\"description\": \"Use this function to get answers based on index path of document.\",\n",
        "\n",
        "# Flow of User interaction\n",
        "greet the user in first interaction.\n",
        "and introduce yourself --> you can only provide answers to question based on collection exists in database and list the collections name\n",
        "using get_collection tool\n",
        "\n",
        "if user collection does not exist ask user to provide pdf path and create collection based on pdf path using tool create_pdf_collection\n",
        "pdf path name will be collection name to use. collection creation takes few seconds to ask user to wait few seconds.\n",
        "\n",
        "if index of document avaialble then first try get_toc_content tool to get answer for user query using index path\n",
        "if answer not found satisfactory use get_answer tool to get answer for user query using collection name\n",
        "\n",
        "if user provide collection name , that collection name will be used to answer user query using get_answer tool.\n",
        "you can call get_answer tool multiple time for multiple questions\n",
        "\n",
        "if user chat_history available then collection name based on latest chats will be used to answer query\n",
        "\n",
        "YOUR ONLY TASK TO ANSWER USER QUERY BASED ON COLLECTION/indexpath AVAILABLE ON DATABASE.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# out = await chat_bot(chat_history)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b4364551650040c5a48fb017f6bb4e42",
            "0073a34d6dc24c93af21350fe5b917bf",
            "f93e3ddb98bb493396312b178a555dca",
            "2747f99740024630be498c2ca56272a4",
            "3519a290cb814a5a851cc7f6a8dc0fc0",
            "0fb4517735874bdab27c88ba663cb063",
            "df0ff1025ccf4750a4f17dc9a37394e8",
            "aac2959c9e2049099dbc6b2a45e35dd9",
            "812a4b0453fc468eb76e67def7e952bc",
            "b72e693ae9264722baacb09af3df01d7",
            "1bb449f0950748f6a77343d3efe79425"
          ]
        },
        "id": "st_aIm5yESbq",
        "outputId": "2aacb723-61fe-433d-d555-f238645a8bd9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4364551650040c5a48fb017f6bb4e42"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# async def chat_bot(chat_history,recursion_step=0):\n",
        "\n",
        "\n",
        "#     chat_answer = await chat_request(chat_history, tools=tools, stream=False)\n",
        "#     print('recursion step ',recursion_step)\n",
        "\n",
        "#     if hasattr(chat_answer, 'choices') and chat_answer.choices:\n",
        "#         message = chat_answer.choices[0].message\n",
        "#         if hasattr(message, 'content') and message.content:\n",
        "#             print(f\"\\nResponse: {message.content}\")\n",
        "#             assistant_msg = [{\"role\": \"assistant\", \"content\": message.content}]\n",
        "#             chat_history += assistant_msg\n",
        "\n",
        "#         if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "#             output_json = {}\n",
        "#             for call in message.tool_calls:\n",
        "\n",
        "#                 if call.function.name == 'get_answer':  # Corrected dot notation\n",
        "\n",
        "#                     print('searching answers...')\n",
        "#                     arguments = json.loads(call.function.arguments)\n",
        "#                     query = arguments['query']\n",
        "#                     collection_name = arguments['collection']\n",
        "#                     ans,_ = await get_answer(query,collection_name)\n",
        "#                     output_json[query] = ans['answer']\n",
        "#                     assistant_msg = [{\"role\": \"assistant\", \"content\": f\"answer from database for {query}: {ans['answer']}\"}]\n",
        "#                     chat_history += assistant_msg\n",
        "\n",
        "#                 if call.function.name == 'get_collections':\n",
        "\n",
        "#                     print('fetching collection list...')\n",
        "#                     collection_list = get_collections()\n",
        "#                     if collection_list:\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection list {collection_list}'}]\n",
        "#                     else:\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection list is empty'}]\n",
        "#                     chat_history += assistant_msg\n",
        "#                     chat_answer = await chat_bot(chat_history,recursion_step+1)\n",
        "\n",
        "#                 if call.function.name == 'create_pdf_collection':\n",
        "\n",
        "#                     print('creating collection...')\n",
        "#                     arguments = json.loads(call.function.arguments)\n",
        "#                     path = arguments['pdf_path']\n",
        "#                     status,collection_name = create_pdf_collection(path)\n",
        "#                     if status=='success':\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection created with collection name {collection_name}'}]\n",
        "#                     else:\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection creation failed contact support'}]\n",
        "#                     chat_history += assistant_msg\n",
        "#                     chat_answer = await chat_bot(chat_history,recursion_step+1)\n",
        "\n",
        "\n",
        "#             if output_json:\n",
        "#                 print(\"\\nGenerated JSON Output:\")\n",
        "#                 print(json.dumps(output_json, indent=2))\n",
        "#                 # assistant_msg = [{\"role\": \"assistant\", \"content\": f' response from database {json.dumps(output_json, indent=2)}'}]\n",
        "#                 # chat_history += assistant_msg\n",
        "#                 chat_answer = await chat_bot(chat_history,recursion_step+1)\n",
        "#             # assistant_msg\n",
        "\n",
        "#     return chat_history"
      ],
      "metadata": {
        "id": "ogeRJDrIESY4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# async def chat_bot(chat_history, recursion_step=0):\n",
        "#     chat_answer = await chat_request(chat_history, tools=tools, stream=False)\n",
        "#     print('recursion step ', recursion_step)\n",
        "\n",
        "#     if hasattr(chat_answer, 'choices') and chat_answer.choices:\n",
        "#         message = chat_answer.choices[0].message\n",
        "#         if hasattr(message, 'content') and message.content:\n",
        "#             print(f\"\\nResponse: {message.content}\")\n",
        "#             assistant_msg = [{\"role\": \"assistant\", \"content\": message.content}]\n",
        "#             chat_history += assistant_msg\n",
        "\n",
        "#         if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "#             output_json = {}\n",
        "#             needs_recursive_call = False\n",
        "\n",
        "#             for call in message.tool_calls:\n",
        "#                 if call.function.name == 'get_answer':\n",
        "#                     print('searching answers...')\n",
        "#                     arguments = json.loads(call.function.arguments)\n",
        "#                     query = arguments['query']\n",
        "#                     collection_name = arguments['collection']\n",
        "#                     ans, _ = await get_answer(query, collection_name)\n",
        "#                     output_json[query] = ans['answer']\n",
        "#                     assistant_msg = [{\"role\": \"assistant\", \"content\": f\"answer from database for {query}: {ans['answer']}\"}]\n",
        "#                     chat_history += assistant_msg\n",
        "\n",
        "#                 elif call.function.name == 'get_collections':\n",
        "#                     print('fetching collection list...')\n",
        "#                     collection_list = get_collections()\n",
        "#                     if collection_list:\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection list {collection_list}'}]\n",
        "#                     else:\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection list is empty'}]\n",
        "#                     chat_history += assistant_msg\n",
        "#                     needs_recursive_call = True\n",
        "\n",
        "#                 elif call.function.name == 'create_pdf_collection':\n",
        "#                     print('creating collection...')\n",
        "#                     arguments = json.loads(call.function.arguments)\n",
        "#                     path = arguments['pdf_path']\n",
        "#                     status, collection_name = create_pdf_collection(path)\n",
        "#                     if status == 'success':\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection created with collection name {collection_name}'}]\n",
        "#                     else:\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection creation failed contact support'}]\n",
        "#                     chat_history += assistant_msg\n",
        "#                     needs_recursive_call = True\n",
        "\n",
        "#             if output_json:\n",
        "#                 print(\"\\nGenerated JSON Output:\")\n",
        "#                 print(json.dumps(output_json, indent=2))\n",
        "\n",
        "#             if needs_recursive_call:\n",
        "#                 chat_answer = await chat_bot(chat_history, recursion_step+1)\n",
        "\n",
        "#     return chat_history"
      ],
      "metadata": {
        "id": "nwo2l9GLR3C8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# async def chat_bot(chat_history, recursion_step=0):\n",
        "#     chat_answer = await chat_request(chat_history, tools=tools, stream=False)\n",
        "#     print('recursion step ', recursion_step)\n",
        "\n",
        "#     if hasattr(chat_answer, 'choices') and chat_answer.choices:\n",
        "#         message = chat_answer.choices[0].message\n",
        "#         if hasattr(message, 'content') and message.content:\n",
        "#             print(f\"\\nResponse: {message.content}\")\n",
        "#             assistant_msg = [{\"role\": \"assistant\", \"content\": message.content}]\n",
        "#             chat_history += assistant_msg\n",
        "\n",
        "#         if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "#             output_json = {}\n",
        "#             tool_responses_added = False\n",
        "\n",
        "#             for call in message.tool_calls:\n",
        "#                 if call.function.name == 'get_answer':\n",
        "#                     print('searching answers...')\n",
        "#                     arguments = json.loads(call.function.arguments)\n",
        "#                     query = arguments['query']\n",
        "#                     collection_name = arguments['collection']\n",
        "#                     ans, _ = await get_answer(query, collection_name)\n",
        "#                     output_json[query] = ans['answer']\n",
        "#                     assistant_msg = [{\"role\": \"assistant\", \"content\": f\"answer from database for {query}: {ans['answer']}\"}]\n",
        "#                     chat_history += assistant_msg\n",
        "#                     tool_responses_added = True\n",
        "\n",
        "#                 elif call.function.name == 'get_collections':\n",
        "#                     print('fetching collection list...')\n",
        "#                     collection_list = get_collections()\n",
        "#                     if collection_list:\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection list {collection_list}'}]\n",
        "#                     else:\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection list is empty'}]\n",
        "#                     chat_history += assistant_msg\n",
        "#                     tool_responses_added = True\n",
        "\n",
        "#                 elif call.function.name == 'create_pdf_collection':\n",
        "#                     print('creating collection...')\n",
        "#                     arguments = json.loads(call.function.arguments)\n",
        "#                     path = arguments['pdf_path']\n",
        "#                     status, collection_name = create_pdf_collection(path)\n",
        "#                     if status == 'success':\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection created with collection name {collection_name}'}]\n",
        "#                     else:\n",
        "#                         assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection creation failed contact support'}]\n",
        "#                     chat_history += assistant_msg\n",
        "#                     tool_responses_added = True\n",
        "\n",
        "#             if output_json:\n",
        "#                 print(\"\\nGenerated JSON Output:\")\n",
        "#                 print(json.dumps(output_json, indent=2))\n",
        "\n",
        "#             # Make a single recursive call after tool responses are added\n",
        "#             if tool_responses_added and recursion_step < 2:  # Limit recursion depth\n",
        "#                 chat_answer = await chat_bot(chat_history, recursion_step + 1)\n",
        "\n",
        "#     return chat_history"
      ],
      "metadata": {
        "id": "CnX899AATZ2S"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def chat_bot_v2(chat_history, recursion_step=0, previous_actions=None):\n",
        "    print(f'recursion step {recursion_step}, previous actions: {previous_actions}')\n",
        "\n",
        "    previous_actions = previous_actions or set()\n",
        "    chat_answer = await chat_request(chat_history, tools=tools, stream=False)\n",
        "\n",
        "    if hasattr(chat_answer, 'choices') and chat_answer.choices:\n",
        "        message = chat_answer.choices[0].message\n",
        "        if hasattr(message, 'content') and message.content:\n",
        "            print(f\"\\nResponse: {message.content}\")\n",
        "            assistant_msg = [{\"role\": \"assistant\", \"content\": message.content}]\n",
        "            chat_history += assistant_msg\n",
        "\n",
        "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "            output_json = {}\n",
        "            current_actions = set()\n",
        "            tool_calls_processed = False\n",
        "\n",
        "            has_get_answer = any(call.function.name == 'get_answer' for call in message.tool_calls)\n",
        "            has_get_toc_content = any(call.function.name == 'get_toc_content' for call in message.tool_calls)\n",
        "\n",
        "            for call in message.tool_calls:\n",
        "                if call.function.name == 'get_answer' and (recursion_step == 0 or 'get_answer' not in previous_actions):\n",
        "                    print('searching answers...')\n",
        "                    arguments = json.loads(call.function.arguments)\n",
        "                    query = arguments['query']\n",
        "                    collection_name = arguments['collection']\n",
        "                    ans, _ = await get_answer(query, collection_name)\n",
        "                    output_json[query] = ans['answer']\n",
        "                    assistant_msg = [{\"role\": \"assistant\", \"content\": f\"answer from database for {query}: {ans['answer']}\"}]\n",
        "                    chat_history += assistant_msg\n",
        "                    current_actions.add('get_answer')\n",
        "                    tool_calls_processed = True\n",
        "\n",
        "                elif call.function.name == 'get_toc_content' and (recursion_step == 0 or 'get_toc_content' not in previous_actions):\n",
        "                    print('searching toc answers...')\n",
        "                    arguments = json.loads(call.function.arguments)\n",
        "                    query = arguments['query']\n",
        "                    index_name = arguments['index_name']\n",
        "                    ans, _ = await get_toc_content(query, index_name)\n",
        "                    output_json[query] = ans['answer']\n",
        "                    assistant_msg = [{\"role\": \"assistant\", \"content\": f\"answer from database for {query}: {ans['answer']}\"}]\n",
        "                    chat_history += assistant_msg\n",
        "                    current_actions.add('get_toc_content')\n",
        "                    tool_calls_processed = True\n",
        "\n",
        "                elif call.function.name == 'get_collections' and 'get_collections' not in previous_actions:\n",
        "                    print('fetching collection list...')\n",
        "                    collection_list = get_collections()\n",
        "                    if collection_list:\n",
        "                        assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection list {collection_list}'}]\n",
        "                    else:\n",
        "                        assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection list is empty'}]\n",
        "                    chat_history += assistant_msg\n",
        "                    current_actions.add('get_collections')\n",
        "                    tool_calls_processed = True\n",
        "\n",
        "                elif call.function.name == 'create_pdf_collection' and 'create_pdf_collection' not in previous_actions:\n",
        "                    print('creating collection...')\n",
        "                    arguments = json.loads(call.function.arguments)\n",
        "                    path = arguments['pdf_path']\n",
        "                    status, collection_name, index_info = await create_pdf_collection(path)\n",
        "                    if status == 'success':\n",
        "                        assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection created with collection name {collection_name} and index information at path: {index_info}'}]\n",
        "                    else:\n",
        "                        assistant_msg = [{\"role\": \"assistant\", \"content\": f'database collection creation failed contact support'}]\n",
        "                    chat_history += assistant_msg\n",
        "                    current_actions.add('create_pdf_collection')\n",
        "                    tool_calls_processed = True\n",
        "\n",
        "            if output_json:\n",
        "                print(\"\\nGenerated JSON Output:\")\n",
        "                print(json.dumps(output_json, indent=2))\n",
        "\n",
        "            # Make recursive call only if:\n",
        "            # 1. We processed some tool calls\n",
        "            # 2. We're in step 0 and need assistant's final response\n",
        "            if tool_calls_processed and recursion_step == 0 and (has_get_answer or has_get_toc_content):\n",
        "                print(f'Making recursive call with previous_actions: {current_actions}')\n",
        "                chat_answer = await chat_bot_v2(chat_history, recursion_step + 1, current_actions)\n",
        "\n",
        "    return chat_history"
      ],
      "metadata": {
        "id": "z7ekjx7lVoLE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf /content/chromadb_folder"
      ],
      "metadata": {
        "id": "05a0ZpxxQcMM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chat_history = []\n",
        "# system_msg = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "# chat_history = system_msg\n",
        "\n",
        "while True:\n",
        "    user_input = input('your input: ',).strip()\n",
        "    if user_input.lower() == 'q':\n",
        "        print('Response: Goodbye!!')\n",
        "        break\n",
        "\n",
        "    else:\n",
        "        user_msg = [{\"role\": \"user\", \"content\": user_input}]\n",
        "        chat_history = chat_history+user_msg\n",
        "        tokens = count_tokens(json.dumps(chat_history))\n",
        "        if tokens > 100000:\n",
        "            print('Response: Context lenght exceeds. Quiting the chat. Please start fresh!!')\n",
        "            break\n",
        "        # chat_history = await chat_bot(chat_history)\n",
        "        chat_history = await chat_bot_v2(chat_history)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-TVpYrLESV7",
        "outputId": "90f8e98f-b380-4da5-d654-8af83eb597b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your input: tell me about pay rise\n",
            "recursion step 0, previous actions: None\n",
            "searching answers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated JSON Output:\n",
            "{\n",
            "  \"pay rise\": \"Depending on financial health and other Company factors, efforts will be made to give pay raises consistent with Zania, Inc. profitability, job performance, and the consumer price index. The Company may also make individual pay raises based on merit or due to a change of job position.\"\n",
            "}\n",
            "Making recursive call with previous_actions: {'get_answer'}\n",
            "recursion step 1, previous actions: {'get_answer'}\n",
            "\n",
            "Response: Here are the details about pay rises:\n",
            "\n",
            "Depending on the financial health and other factors of the company, Zania, Inc. aims to provide pay raises that are consistent with the company's profitability, job performance, and the consumer price index. Additionally, individual pay raises may be granted based on merit or due to a change in job position.\n",
            "\n",
            "If you have any more questions or need further information, feel free to ask!\n",
            "your input: provide answer based on index\n",
            "recursion step 0, previous actions: None\n",
            "searching toc answers...\n",
            "looking for context at pages:  [11]\n",
            "\n",
            "Generated JSON Output:\n",
            "{\n",
            "  \"pay rise\": \"Data Not Available\"\n",
            "}\n",
            "Making recursive call with previous_actions: {'get_toc_content'}\n",
            "recursion step 1, previous actions: {'get_toc_content'}\n",
            "\n",
            "Response: It seems that I couldn't find specific details about pay rises in the index. If you have any other questions or need information on a different topic, please let me know!\n",
            "your input: ok\n",
            "recursion step 0, previous actions: None\n",
            "\n",
            "Response: If you have any more questions in the future or need assistance, feel free to reach out. Have a great day!\n",
            "your input: q\n",
            "Response: Goodbye!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtKKPRxBKF9E",
        "outputId": "c18c5eca-c140-4cb0-9ad7-c13e60bc636e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': '\\nYour task is to answer user questions. The user can ask a single question or multiple questions.\\nYou have access to the below tools to return answers based on user single/multiple questions.\\n\\n# Tool\\n\"name\": \"get_collections\",\\n\"description\": \"Use this function to check exsiting collection in database\",\\n\"name\": \"create_pdf_collection\",\\n\"description\": \"Use this function to create database collection from pdf file path\",\\n\"name\": \"get_answer\",\\n\"description\": \"Use this function to get answers based on context documents from database to user questions. The documents are purely based on user db.\",\\n                     \\n# Flow of User interaction\\ngreet the user in first interaction.\\nand introduce yourself --> you can only provide answers to question based on collection exists in database and list the collections name\\nusing get_collection tool\\n\\nif user collection does not exist ask user to provide pdf path and create collection based on pdf path using tool create_pdf_collection\\npdf path name will be collection name to use. collection creation takes few seconds to ask user to wait few seconds.\\n\\nif user provide collection name , that collection name will be used to answer user query using get_answer tool.\\nyou can call get_answer tool multiple time for multiple questions\\n\\nif user chat_history available then collection name based on latest chats will be used to answer query\\n\\nYOUR ONLY TASK TO ANSWER USER QUERY BASED ON COLLECTION AVAILABLE ON DATABASE.\\n'},\n",
              " {'role': 'user', 'content': 'hi'},\n",
              " {'role': 'assistant',\n",
              "  'content': \"Hello! I'm here to help you with your questions. I can provide answers based on specific collections in our database. Let me check the existing collections for you. Please hold on for a moment.\"},\n",
              " {'role': 'assistant', 'content': \"database collection list ['handbook.pdf']\"},\n",
              " {'role': 'assistant',\n",
              "  'content': 'I found an existing collection named \"handbook.pdf\" in the database. You can ask me questions related to this collection. What would you like to know?'},\n",
              " {'role': 'user', 'content': 'index saved at /content/handbook.pdf_index.txt'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'It seems like you have provided an index path. However, I currently only have access to the collection named \"handbook.pdf.\" If you have questions related to this collection, feel free to ask!'},\n",
              " {'role': 'user', 'content': 'tell me about sick pay'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'answer from database for sick pay: Data Not Available'},\n",
              " {'role': 'user', 'content': 'based on index , get my sick pay details'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'answer from database for sick pay details: Zania, Inc. allows its regular full-time employees who have completed their introductory period [[#]] sick days per calendar year. Notify your Manager as far in advance as possible if you are going to take sick time off. There may be occasions, such as sudden illness, when you cannot notify your Manager in advance. In those situations, provide notification of your circumstances as soon as possible. You may also be requested to provide a certificate of illness to your Manager. You may use sick leave benefits for dental or doctor visits or to care for immediate family members who are sick. There may also be state mandated use of sick time. Unused sick days may not be converted to a cash payment. You may be required to use available sick leave during family and medical leave, disability leave, or other leave.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Here are the details about sick pay from the index:\\n\\nZania, Inc. allows its regular full-time employees who have completed their introductory period a certain number of sick days per calendar year. You should notify your Manager as far in advance as possible if you are going to take sick time off. In cases of sudden illness, you should provide notification of your circumstances as soon as possible.\\n\\nYou may also be requested to provide a certificate of illness to your Manager. Sick leave benefits can be used for dental or doctor visits or to care for immediate family members who are sick. There may also be state-mandated use of sick time. \\n\\nPlease note that unused sick days may not be converted to cash payment, and you may be required to use available sick leave during family and medical leave, disability leave, or other leave.\\n\\nIf you have any more questions or need further information, feel free to ask!'},\n",
              " {'role': 'user', 'content': 'tell me about pay rise'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'answer from database for pay rise: Depending on financial health and other Company factors, efforts will be made to give pay raises consistent with Zania, Inc. profitability, job performance, and the consumer price index. The Company may also make individual pay raises based on merit or due to a change of job position.'},\n",
              " {'role': 'assistant',\n",
              "  'content': \"Here are the details about pay rises:\\n\\nDepending on the financial health and other factors of the company, Zania, Inc. aims to provide pay raises that are consistent with the company's profitability, job performance, and the consumer price index. Additionally, individual pay raises may be granted based on merit or due to a change in job position.\\n\\nIf you have any more questions or need further information, feel free to ask!\"},\n",
              " {'role': 'user', 'content': 'provide answer based on index'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'answer from database for pay rise: Data Not Available'},\n",
              " {'role': 'assistant',\n",
              "  'content': \"It seems that I couldn't find specific details about pay rises in the index. If you have any other questions or need information on a different topic, please let me know!\"},\n",
              " {'role': 'user', 'content': 'ok'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'If you have any more questions in the future or need assistance, feel free to reach out. Have a great day!'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_history = [{'role': 'system',\n",
        "  'content': '\\nYour task is to answer user questions. The user can ask a single question or multiple questions.\\nYou have access to the below tools to return answers based on user single/multiple questions.\\n\\n# Tool\\n\"name\": \"get_collections\",\\n\"description\": \"Use this function to check exsiting collection in database\",\\n\"name\": \"create_pdf_collection\",\\n\"description\": \"Use this function to create database collection from pdf file path\",\\n\"name\": \"get_answer\",\\n\"description\": \"Use this function to get answers based on context documents from database to user questions. The documents are purely based on user db.\",\\n                     \\n# Flow of User interaction\\ngreet the user in first interaction.\\nand introduce yourself --> you can only provide answers to question based on collection exists in database and list the collections name\\nusing get_collection tool\\n\\nif user collection does not exist ask user to provide pdf path and create collection based on pdf path using tool create_pdf_collection\\npdf path name will be collection name to use. collection creation takes few seconds to ask user to wait few seconds.\\n\\nif user provide collection name , that collection name will be used to answer user query using get_answer tool.\\nyou can call get_answer tool multiple time for multiple questions\\n\\nif user chat_history available then collection name based on latest chats will be used to answer query\\n\\nYOUR ONLY TASK TO ANSWER USER QUERY BASED ON COLLECTION AVAILABLE ON DATABASE.\\n'},\n",
        " {'role': 'user', 'content': 'hi'},\n",
        " {'role': 'assistant',\n",
        "  'content': \"Hello! I'm here to help you with your questions. I can provide answers based on specific collections in our database. Let me check the existing collections for you. Please hold on for a moment.\"},\n",
        " {'role': 'assistant', 'content': \"database collection list ['handbook.pdf']\"},\n",
        " {'role': 'assistant',\n",
        "  'content': 'I found an existing collection named \"handbook.pdf\" in the database. You can ask me questions related to this collection. What would you like to know?'},\n",
        " {'role': 'user', 'content': f'answer all these what is company name, who is ceo of company'}]"
      ],
      "metadata": {
        "id": "pgZdgie2OFCN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = await chat_request(test_history, tools=tools, stream=False)"
      ],
      "metadata": {
        "id": "xQ5lFyNjODZG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.choices[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXjLQTZpOZ3D",
        "outputId": "cf231f16-32f2-47f1-c12f-1bcf786a77e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_aWXlw9rqzFpTL0KCEvGAsTiY', function=Function(arguments='{\"query\": \"What is the company name?\", \"collection\": \"handbook.pdf\"}', name='get_answer'), type='function'), ChatCompletionMessageToolCall(id='call_oVjeFU18dZIy2LvYhpt4DwgZ', function=Function(arguments='{\"query\": \"Who is the CEO of the company?\", \"collection\": \"handbook.pdf\"}', name='get_answer'), type='function')]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import fitz\n",
        "# check_pdf_prompt = ''' Analyze the page content and return True if page as table of content information.\n",
        "# return json output {'toc': true or false}. pdf_page is\n",
        "'''\n",
        "# async def chat_completion_request(messages: List[Dict], model='gpt-4o-mini') -> Any:\n",
        "#     \"\"\"Make a chat completion request with retry logic.\"\"\"\n",
        "#     try:\n",
        "#         params = {\n",
        "#             'messages': messages,\n",
        "#             'max_tokens': 500,\n",
        "#             'model': model,\n",
        "#             'temperature': 0,\n",
        "#             'response_format': {\"type\": \"json_object\"}\n",
        "#         }\n",
        "\n",
        "#         response = await generate_response(params)\n",
        "#         return response\n",
        "#     except Exception as e:\n",
        "#         logger.error(f\"Chat completion request failed: {str(e)}\", exc_info=True)\n",
        "#         raise\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "kdqfPIktOgdL",
        "outputId": "9f210456-a8d9-4d27-d9cc-d6808013cf09"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-38-aa6bfea7a4d6>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-aa6bfea7a4d6>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# async def get_toc_content(query,index_name):\n",
        "\n",
        "\n",
        "#   with open(f'{index_name}','r') as f:\n",
        "#     content = f.read()\n",
        "#     prompt = f'''\n",
        "#   Your task is to return list of page no which may contain information regarding {query}\n",
        "#   based on this table of content {content} output format: json page:[page no]\n",
        "#   '''\n",
        "#     msg = [{\"role\": \"system\", \"content\": prompt}]\n",
        "#     response = await chat_completion_request(msg)\n",
        "#     output = json.loads(response.choices[0].message.content)\n",
        "#     pdf_path = index_name.split('_index')[0]\n",
        "#     doc = fitz.open(pdf_path)\n",
        "#     print('looking for context at pages: ', output['page'])\n",
        "#     context = [doc.load_page(page_num-1).get_text() for page_num in output['page']]\n",
        "#     return context\n",
        "\n",
        "    #\n",
        "    # doc_name = doc.name.split('/')[-1]\n",
        "    # Iterate through each page\n",
        "\n",
        "\n",
        "out = await get_toc_content('what is sick pay','pdf-rag/handbook.pdf_index.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H57kzjoFh53G",
        "outputId": "35c8cc3f-6742-41b6-d9ee-e842696050bf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looking for context at pages:  [24, 40, 41]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "O0qV0X6bFLMV",
        "outputId": "6c7ebaa9-0245-4baf-eab5-d345672ffd15"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"retains the discretion to determine the similarity of any available positions and your qualifications. If we are unable to\\nreinstate you or you refuse the offer of reinstatement to a different position, your leave status will be changed to a voluntary\\ntermination.\\nFailure to Return from Leave\\nIf you fail to return to work after an unpaid leave of absence, you will be considered to have resigned your employment.\\nAlternative Employment\\nWhile on an unpaid leave of absence, you may not work or be gainfully employed either for yourself or others unless\\nexpress, written permission to perform such outside work has been granted by the Company. If you are on a leave of\\nabsence and are found to be working elsewhere without permission, you will be subject to disciplinary action up to and\\nincluding termination.\\n7.6 Sick Pay\\nZania, Inc. allows its regular full-time employees who have completed their introductory period [[#]] sick days per calendar\\nyear. Notify your Manager as far in advance as possible if you are going to take sick time off. There may be occasions, such\\nas sudden illness, when you cannot notify your Manager in advance. In those situations, provide notification of your\\ncircumstances as soon as possible. You may also be requested to provide a certificate of illness to your Manager.\\nYou may use sick leave benefits for dental or doctor visits or to care for immediate family members who are sick. There may\\nalso be state mandated use of sick time. Unused sick days may not be converted to a cash payment. You may be required\\nto use available sick leave during family and medical leave, disability leave, or other leave.\\n[[Sick time accumulation will be capped at a total of [#] days per year.]]\\n7.7 Vacation\\nZania, Inc. provides employees with paid vacation.\\nEligibility\\nAll [[full-time regular]] employees are eligible to receive vacation time [[immediately upon hire/upon completion of the\\nintroductory period/after completing # days of employment]].\\nDeposits Into Your Leave Account\\nVacation is calculated according to [[your work anniversary year/the calendar year/the fiscal year, which begins on [date]\\nand ends on [date]]]. \\n[[EMPLOYERS MUST CHOOSE ONE:]]\\n[[Option 1:]]\\nThe amount of vacation received each year is based on your length of service and [[is granted in a lump sum at the\\nbeginning of each year/accrues according to an accrual schedule determined by the Company up to a maximum annual\\ngrant as shown below]]:\\nFirst year of employment: [[# hours/days/weeks]] annually.\\nSecond and third year of employment: [[# hours/days/weeks]] annually.\\nThird through fifth year of employment: [[# hours/days/weeks]] annually.\\nOver five years of employment: [[# hours/days/weeks]] annually.\\nPart-time regular employees receive vacation time in proportion to their work schedule.\\n24\\n The Company reserves the right to require employees to provide proof of jury duty service to the extent authorized by law.\\nThe Company will not retaliate against employees who request or take leave in accordance with this policy.\\nPaid Family Leave Insurance\\nCalifornia's Paid Family Leave (PFL) insurance program provides eligible employees with up to eight weeks of partial wage\\nreplacement in any 12-month period to take time off from work to:\\nBond with a new child (either by birth, adoption, or foster care placement);\\nCare for a seriously ill family member (child, parent, parent-in-law, grandparent, grandchild, sibling, spouse, or\\nregistered domestic partner); or\\nParticipate in a qualifying exigency related to the covered active duty, or call to covered active duty, of your spouse,\\ndomestic partner, child, or parent in the U.S. Armed Forces.\\nThe 12-month period begins on the day a claim is submitted.\\nPFL insurance is funded entirely by workers through state disability insurance (SDI) payroll deductions. If you are currently\\nreceiving benefits from SDI or workers' compensation insurance, you may not be eligible to receive PFL benefits. The\\nCalifornia PFL insurance program does not create a right to a leave of absence, job protection, or job reinstatement.\\nThe PFL insurance program makes benefits available to eligible employees through the California Employment\\nDevelopment Department (EDD). Apply for PFL insurance directly with the EDD. Contact the EDD for information on\\neligibility or to obtain a claim form. Medical and other documentation may be required.\\nPaid Sick Leave (Accrual Method)\\nZania, Inc. provides paid sick leave to all eligible employees in accordance with California's Healthy Workplaces, Healthy\\nFamilies Act.\\nEligibility\\nAll employees who have worked in California for at least 30 days within a year after beginning employment are entitled to\\nearn sick leave.\\nReasons for Leave\\nSick leave may be taken for the following reasons:\\nThe diagnosis, care, or treatment of an existing health condition, or preventive care for you or your family member.\\nTo seek care, psychological counseling, shelter or support services, safety-related measures, or any relief, including\\nrestraining orders, to help ensure your own or your child's health, safety, or welfare if you or your child is a victim of\\ndomestic violence, sexual assault, or stalking.\\nFamily member means:\\nYour children (including biological, adopted, or foster children, legal wards, children of a domestic partner, or children\\nfor whom you stand in loco parentis).\\nYour spouse or registered domestic partner.\\nYour parents or your spouse's or registered domestic partner's parents (including biological, foster, and stepparents;\\nadoptive parents; legal guardians; or persons who stood in loco parentis when you, or your spouse or domestic\\npartner, was a minor child).\\nYour grandparents.\\nYour grandchildren.\\nYour siblings.\\nA person designated by you at the time you request paid sick leave. [[You will be limited to making this designation\\n40\\n once per 12-month period for purposes of paid sick leave.]]\\nAccrual and Usage\\nEligible employees begin to accrue sick leave upon employment at a rate of one hour for every 30 hours worked and may\\nbegin using accrued leave on the 90th day of employment. \\nYou may not use more sick leave than you have accrued or receive an advance of sick leave that has not yet been accrued.\\nEarned but unused sick leave will carry over to the following leave year up to a maximum of 48 hours (six days). For the\\npurposes of this policy, the leave year is [[any consecutive 12-month period (e.g., calendar year, fiscal year, employee work\\nanniversary, etc.)]]. \\nYou may only use up to 24 hours (three days) of your available earned paid sick leave per leave year. Paid sick leave may\\nbe taken in no less than two-hour increments.\\nNotice\\nIf your need for leave is foreseeable, you must provide as much advance notice as possible. If unforeseeable, provide notice\\nas soon as practical. If known, notice should include the expected length of the absence.\\nDocumentation\\nThe Company may request documentation verifying the appropriate use of leave.\\nPayment upon Termination\\nYou will not be paid for any unused sick leave when your employment ends.\\nReinstatement of Sick Leave upon Rehire\\nThe Company will reinstate previously accrued, unused sick leave if you separate and are rehired within one year.\\nInteraction with Other Leave\\nSick leave will run concurrently with other types of leave where permitted under applicable law.\\nRetaliation\\nThe Company will not retaliate against employees who request or take leave in accordance with this policy.\\nPaid Sick Leave (Frontloading Method)\\nZania, Inc. provides paid sick leave to all eligible employees in accordance with California's Healthy Workplaces, Healthy\\nFamilies Act.\\nEligibility\\nAll employees who have worked in California for at least 30 days within a year after beginning employment are entitled to\\nreceive sick leave.\\nReasons for Leave\\nSick leave may be taken for the following reasons:\\nThe diagnosis, care, or treatment of an existing health condition, or preventive care for you or your family member.\\nTo seek care, psychological counseling, shelter or support services, safety-related measures, or any relief, including\\nrestraining orders, to help ensure your own or your child's health, safety, or welfare if you or your child is a victim of\\ndomestic violence, sexual assault, or stalking.\\n41\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(' '.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugncWg3zDdfK",
        "outputId": "2329c59d-6328-4672-82a5-54e95fd3a905"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1721"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heCmEHhzahIS",
        "outputId": "074d4936-c89f-4c6c-afc6-682580ca9ba7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz"
      ],
      "metadata": {
        "id": "TK2HmUKzdW9P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_by_page(pdf_path):\n",
        "    # Open the provided PDF file\n",
        "    page_content_dict = {}\n",
        "    doc = fitz.open(pdf_path)\n",
        "    doc_name = doc.name.split('/')[-1]\n",
        "    # Iterate through each page\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)  # Load the current page\n",
        "        text = page.get_text()  # Extract text from the page\n",
        "        page_number = page_num+1\n",
        "\n",
        "        if page_content_dict.get(page_number,None):\n",
        "            page_content_dict[page_number]+='\\n'.join([text])\n",
        "        else:\n",
        "            page_content_dict[page_number] = text\n",
        "\n",
        "        # print(f\"--- Page {page_num + 1} ---\\n{text}\")\n",
        "\n",
        "    doc.close()\n",
        "\n",
        "    return page_content_dict, doc_name"
      ],
      "metadata": {
        "id": "AZwwKeBpdZyN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_json,_ = extract_text_by_page('pdf-rag/handbook.pdf')"
      ],
      "metadata": {
        "id": "Y6P7nx05dqkS"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_json[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "pNCF-72Idzev",
        "outputId": "b53797c2-0246-432f-f369-7b43db227dfc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TABLE OF CONTENTS\\nCORE POLICIES\\n4\\n1.0 WELCOME\\n4\\n1.1 A Welcome Policy\\n4\\n1.2 At-Will Employment\\n4\\n2.0 INTRODUCTORY LANGUAGE AND POLICIES\\n5\\n2.1 About the Company\\n5\\n2.2 Company Facilities\\n5\\n2.3 Ethics Code\\n5\\n2.4 Mission Statement\\n5\\n2.5 Our Organization\\n5\\n2.6 Revisions to Handbook\\n5\\n3.0 HIRING AND ORIENTATION POLICIES\\n5\\n3.1 Accommodations for Pregnant Employees\\n5\\n3.2 Conflicts of Interest\\n6\\n3.3 Employment Authorization Verification\\n6\\n3.4 Employment of Relatives and Friends\\n6\\n3.5 Job Descriptions\\n7\\n3.6 New Hires and Introductory Periods\\n7\\n3.7 Training Program\\n7\\n4.0 WAGE AND HOUR POLICIES\\n7\\n4.1 Attendance\\n7\\n4.2 Business Expenses\\n7\\n4.3 Direct Deposit\\n8\\n4.4 Employment Classifications\\n8\\n4.5 Introduction to Wage and Hour Policies\\n8\\n4.6 Job Abandonment\\n9\\n4.7 Paycheck Deductions\\n9\\n4.8 Recording Time\\n9\\n4.9 Travel Expenses\\n10\\n4.10 Use of Employer Credit Cards\\n11\\n5.0 PERFORMANCE, DISCIPLINE, LAYOFF, AND TERMINATION\\n11\\n5.1 Criminal Activity/Arrests\\n11\\n5.2 Disciplinary Process\\n11\\n5.3 Exit Interview\\n12\\n5.4 Open Door/Conflict Resolution Process\\n12\\n5.5 Outside Employment\\n12\\n5.6 Pay Raises\\n12\\n5.7 Performance Improvement\\n12\\n5.8 Post-Employment References\\n13\\n5.9 Promotions\\n13\\n5.10 Resignation Policy\\n13\\n5.11 Standards of Conduct\\n13\\n5.12 Transfers\\n14\\n5.13 Workforce Reductions (Layoffs)\\n14\\n6.0 GENERAL POLICIES\\n14\\n6.1 Computer Security and Copying of Software\\n14\\n6.2 Employer Sponsored Social Events\\n15\\n6.3 Employer-Provided Cell Phones/Mobile Devices\\n15\\n6.4 Nonsolicitation/Nondistribution Policy\\n15\\n6.5 Off-Duty Use of Employer Property or Premises\\n16\\n6.6 Personal Appearance\\n16\\n6.7 Personal Cell Phone/Mobile Device Use\\n16\\n6.8 Personal Data Changes\\n17\\n6.9 Security\\n17\\n6.10 Social Media\\n17\\n6.11 Third Party Disclosures\\n19\\n6.12 Use of Company Technology\\n19\\n6.13 Workplace Privacy and Right to Inspect\\n20\\n7.0 BENEFITS\\n20\\n7.1 Bereavement Leave\\n20\\n7.2 Holidays\\n21\\n7.3 Military Leave (USERRA)\\n21\\n7.4 Paid Time Off (PTO)\\n21\\n7.5 Personal Leave of Absence\\n23\\n7.6 Sick Pay\\n24\\n2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://aimistanforddatasets01.blob.core.windows.net/chexpertchestxrays-u20210408?sv=2019-02-02&sr=c&sig=4E5H6PmEWeGe1ewPb8U%2FUbIYo%2Bc9zc%2BfU4jwWlM6AaU%3D&st=2025-01-10T13%3A55%3A06Z&se=2025-02-09T14%3A00%3A06Z&sp=rl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-sqThdqd11C",
        "outputId": "6f4b759c-1167-498b-8580-2f96db3c85c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-10 14:01:36--  https://aimistanforddatasets01.blob.core.windows.net/chexpertchestxrays-u20210408?sv=2019-02-02\n",
            "Resolving aimistanforddatasets01.blob.core.windows.net (aimistanforddatasets01.blob.core.windows.net)... 20.60.229.1\n",
            "Connecting to aimistanforddatasets01.blob.core.windows.net (aimistanforddatasets01.blob.core.windows.net)|20.60.229.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 The specified resource does not exist.\n",
            "2025-01-10 14:01:36 ERROR 404: The specified resource does not exist..\n",
            "\n"
          ]
        }
      ]
    }
  ]
}